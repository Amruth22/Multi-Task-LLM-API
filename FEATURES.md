# ğŸš€ Multi-Task LLM API Features

This document outlines the features and capabilities of the simplified Multi-Task LLM API.

## ğŸ¯ Core Features

### 1. Multi-Task AI Capabilities
- **ğŸ“ Text Generation**: Creative writing, summaries, content creation
- **ğŸ’» Code Generation**: Programming assistance with optimized settings
- **ğŸ·ï¸ Text Classification**: Categorize text into custom categories

### 2. API Design
- **ğŸ”„ RESTful API**: Clean REST endpoints with proper HTTP methods
- **ğŸ“Š Swagger UI**: Interactive API documentation at `/swagger/`
- **ğŸ¥ Health Check**: Monitor API status at `/health`
- **ğŸŒ CORS Support**: Cross-origin resource sharing enabled

### 3. Rate Limiting & Security
- **âš¡ Smart Rate Limiting**: 200/day, 50/hour, 10/minute per endpoint
- **ğŸ” Environment Configuration**: Secure API key management
- **ğŸ›¡ï¸ Input Validation**: Proper request validation and error handling

### 4. Reliability Features
- **ğŸ”„ Exponential Backoff**: Intelligent retry logic for API failures
- **âš ï¸ Error Handling**: Graceful error responses with proper HTTP codes
- **ğŸ“¡ Rate Limit Detection**: Automatic handling of Gemini API limits

## ğŸ—ï¸ Technical Architecture

### Model Configuration
| Task | Model | Temperature | Purpose |
|------|-------|-------------|---------|
| Text Generation | Gemini 2.0 Flash | 0.7 | Creative and varied outputs |
| Code Generation | Gemini 2.0 Flash | 0.2 | Consistent and reliable code |
| Text Classification | Gemini 2.0 Flash | 0.0 | Deterministic classification |

### API Endpoints

#### Text Generation
```http
POST /api/v1/generate/text
{
  "prompt": "Your text prompt here"
}
```

#### Code Generation
```http
POST /api/v1/generate/code
{
  "prompt": "Your code request here"
}
```

#### Text Classification
```http
POST /api/v1/classify/text
{
  "text": "Text to classify",
  "categories": ["category1", "category2", "category3"]
}
```

#### Health Check
```http
GET /api/v1/health
```

## ğŸ§ª Testing & Quality Assurance

### Comprehensive Test Suite
- âœ… **Environment Configuration**: API key validation
- âœ… **Flask App Initialization**: Server startup and health checks
- âœ… **Endpoint Functionality**: All three AI capabilities
- âœ… **Error Handling**: Missing fields and invalid requests
- âœ… **Rate Limiting**: Request throttling functionality
- âœ… **Direct Function Testing**: Wrapper function validation
- âœ… **Swagger UI**: Documentation accessibility
- âœ… **Integration Testing**: End-to-end API testing

### Example Usage Script
- ğŸ“‹ **Automated Testing**: `example_usage.py` for quick validation
- ğŸ” **Error Scenarios**: Tests invalid requests and error handling
- ğŸ“Š **Performance Monitoring**: Response time and success rate tracking

## ğŸš€ Deployment Options

### Development
```bash
python app.py
# Runs on http://0.0.0.0:8080
```

### Production
```bash
waitress-serve --host=0.0.0.0 --port=8080 app:app
# Production WSGI server with better performance
```

## ğŸ“¦ Dependencies

### Core Framework
- **Flask**: Web framework
- **Flask-RESTX**: Swagger UI and API documentation
- **Flask-Limiter**: Rate limiting functionality
- **Flask-CORS**: Cross-origin resource sharing

### AI Integration
- **LangChain**: LLM framework and utilities
- **langchain-google-genai**: Google Gemini integration
- **tenacity**: Retry logic and exponential backoff

### Configuration & Utilities
- **python-dotenv**: Environment variable management
- **waitress**: Production WSGI server

## ğŸ”§ Configuration

### Environment Variables
```env
GOOGLE_API_KEY=your_google_api_key_here
```

### Rate Limits
- **Daily**: 200 requests per day
- **Hourly**: 50 requests per hour  
- **Per Minute**: 10 requests per minute per endpoint

### Retry Configuration
- **Max Retries**: 5 attempts
- **Initial Delay**: 1 second
- **Max Delay**: 60 seconds
- **Strategy**: Exponential backoff

## ğŸ“Š API Response Format

### Success Response
```json
{
  "generated_text": "Generated content here...",
  "generated_code": "def example():\n    pass",
  "classification": "positive"
}
```

### Error Response
```json
{
  "error": "Descriptive error message"
}
```

## ğŸ¯ Use Cases

### Text Generation
- **Content Creation**: Blog posts, articles, creative writing
- **Summarization**: Document and text summarization
- **Creative Writing**: Stories, poems, creative content

### Code Generation
- **Function Creation**: Generate specific functions
- **Code Examples**: Create code snippets and examples
- **Algorithm Implementation**: Implement algorithms and data structures

### Text Classification
- **Sentiment Analysis**: Positive, negative, neutral classification
- **Content Categorization**: Topic classification
- **Intent Recognition**: User intent classification

## ğŸ”® Future Enhancements

While this is the simplified version, potential enhancements could include:

- **Authentication**: User authentication and API keys
- **Usage Analytics**: Request tracking and usage statistics
- **Caching**: Response caching for improved performance
- **Database Integration**: Persistent storage for requests/responses
- **Multi-Model Support**: Support for additional AI models
- **Batch Processing**: Handle multiple requests in a single call

## ğŸ“ Getting Started

1. **Clone the repository**
2. **Install dependencies**: `pip install -r requirements.txt`
3. **Configure environment**: Create `.env` with your Google API key
4. **Run the server**: `python app.py`
5. **Test the API**: Use `python example_usage.py`
6. **Explore documentation**: Visit `http://0.0.0.0:8080/swagger/`

## ğŸ¤ Contributing

This simplified API provides a clean foundation for:
- **Learning**: Understanding LLM API development
- **Prototyping**: Quick AI application development
- **Extension**: Building more complex features on top
- **Integration**: Embedding AI capabilities in existing applications

The codebase is designed to be readable, maintainable, and easily extensible for future enhancements.